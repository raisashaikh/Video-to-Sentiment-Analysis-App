{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Installing Dependencies"
      ],
      "metadata": {
        "id": "k_s8PsjO62LH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -r \"/content/drive/MyDrive/Video_analysis/requirements.txt\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "4um3d55p68dk",
        "outputId": "11c7146f-c42c-402e-951a-b63c4797719d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting blinker==1.8.2 (from -r /content/drive/MyDrive/Video_analysis/requirements.txt (line 1))\n",
            "  Downloading blinker-1.8.2-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: certifi==2024.7.4 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/Video_analysis/requirements.txt (line 2)) (2024.7.4)\n",
            "Requirement already satisfied: charset-normalizer==3.3.2 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/Video_analysis/requirements.txt (line 3)) (3.3.2)\n",
            "Requirement already satisfied: click==8.1.7 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/Video_analysis/requirements.txt (line 4)) (8.1.7)\n",
            "Collecting colorama==0.4.6 (from -r /content/drive/MyDrive/Video_analysis/requirements.txt (line 5))\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: Cython==3.0.10 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/Video_analysis/requirements.txt (line 6)) (3.0.10)\n",
            "Requirement already satisfied: decorator==4.4.2 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/Video_analysis/requirements.txt (line 7)) (4.4.2)\n",
            "Collecting dtw-python==1.5.1 (from -r /content/drive/MyDrive/Video_analysis/requirements.txt (line 8))\n",
            "  Downloading dtw_python-1.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.1/48.1 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock==3.15.4 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/Video_analysis/requirements.txt (line 9)) (3.15.4)\n",
            "Collecting Flask==3.0.3 (from -r /content/drive/MyDrive/Video_analysis/requirements.txt (line 10))\n",
            "  Downloading flask-3.0.3-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: fsspec==2024.6.1 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/Video_analysis/requirements.txt (line 11)) (2024.6.1)\n",
            "Requirement already satisfied: idna==3.7 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/Video_analysis/requirements.txt (line 12)) (3.7)\n",
            "Requirement already satisfied: imageio==2.34.2 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/Video_analysis/requirements.txt (line 13)) (2.34.2)\n",
            "Requirement already satisfied: imageio-ffmpeg==0.5.1 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/Video_analysis/requirements.txt (line 14)) (0.5.1)\n",
            "Requirement already satisfied: itsdangerous==2.2.0 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/Video_analysis/requirements.txt (line 15)) (2.2.0)\n",
            "Requirement already satisfied: Jinja2==3.1.4 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/Video_analysis/requirements.txt (line 16)) (3.1.4)\n",
            "Requirement already satisfied: joblib==1.4.2 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/Video_analysis/requirements.txt (line 17)) (1.4.2)\n",
            "Requirement already satisfied: llvmlite==0.43.0 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/Video_analysis/requirements.txt (line 18)) (0.43.0)\n",
            "Requirement already satisfied: MarkupSafe==2.1.5 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/Video_analysis/requirements.txt (line 19)) (2.1.5)\n",
            "Requirement already satisfied: more-itertools==10.3.0 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/Video_analysis/requirements.txt (line 20)) (10.3.0)\n",
            "Requirement already satisfied: moviepy==1.0.3 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/Video_analysis/requirements.txt (line 21)) (1.0.3)\n",
            "Requirement already satisfied: mpmath==1.3.0 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/Video_analysis/requirements.txt (line 22)) (1.3.0)\n",
            "Requirement already satisfied: networkx==3.3 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/Video_analysis/requirements.txt (line 23)) (3.3)\n",
            "Requirement already satisfied: nltk==3.8.1 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/Video_analysis/requirements.txt (line 24)) (3.8.1)\n",
            "Requirement already satisfied: numba==0.60.0 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/Video_analysis/requirements.txt (line 25)) (0.60.0)\n",
            "Requirement already satisfied: numpy==1.26.4 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/Video_analysis/requirements.txt (line 26)) (1.26.4)\n",
            "Collecting openai-whisper==20231117 (from -r /content/drive/MyDrive/Video_analysis/requirements.txt (line 27))\n",
            "  Downloading openai-whisper-20231117.tar.gz (798 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m798.6/798.6 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pillow==10.4.0 (from -r /content/drive/MyDrive/Video_analysis/requirements.txt (line 28))\n",
            "  Downloading pillow-10.4.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: proglog==0.1.10 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/Video_analysis/requirements.txt (line 29)) (0.1.10)\n",
            "Collecting regex==2024.7.24 (from -r /content/drive/MyDrive/Video_analysis/requirements.txt (line 30))\n",
            "  Downloading regex-2024.7.24-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting requests==2.32.3 (from -r /content/drive/MyDrive/Video_analysis/requirements.txt (line 31))\n",
            "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting scipy==1.14.0 (from -r /content/drive/MyDrive/Video_analysis/requirements.txt (line 32))\n",
            "  Downloading scipy-1.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting setuptools==71.1.0 (from -r /content/drive/MyDrive/Video_analysis/requirements.txt (line 33))\n",
            "  Downloading setuptools-71.1.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/Video_analysis/requirements.txt (line 34)) (1.13.1)\n",
            "Collecting tiktoken==0.7.0 (from -r /content/drive/MyDrive/Video_analysis/requirements.txt (line 35))\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting torch==2.4.0 (from -r /content/drive/MyDrive/Video_analysis/requirements.txt (line 36))\n",
            "  Downloading torch-2.4.0-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\n",
            "Requirement already satisfied: tqdm==4.66.4 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/Video_analysis/requirements.txt (line 37)) (4.66.4)\n",
            "Requirement already satisfied: typing_extensions==4.12.2 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/Video_analysis/requirements.txt (line 38)) (4.12.2)\n",
            "Collecting urllib3==2.2.2 (from -r /content/drive/MyDrive/Video_analysis/requirements.txt (line 39))\n",
            "  Downloading urllib3-2.2.2-py3-none-any.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: Werkzeug==3.0.3 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/Video_analysis/requirements.txt (line 40)) (3.0.3)\n",
            "Collecting whisper-timestamped==1.15.4 (from -r /content/drive/MyDrive/Video_analysis/requirements.txt (line 41))\n",
            "  Downloading whisper_timestamped-1.15.4-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting streamlit==1.29.0 (from -r /content/drive/MyDrive/Video_analysis/requirements.txt (line 42))\n",
            "  Downloading streamlit-1.29.0-py2.py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting streamlit-option-menu==0.3.6 (from -r /content/drive/MyDrive/Video_analysis/requirements.txt (line 43))\n",
            "  Downloading streamlit_option_menu-0.3.6-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: triton<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117->-r /content/drive/MyDrive/Video_analysis/requirements.txt (line 27)) (2.3.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.4.0->-r /content/drive/MyDrive/Video_analysis/requirements.txt (line 36))\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.4.0->-r /content/drive/MyDrive/Video_analysis/requirements.txt (line 36))\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.4.0->-r /content/drive/MyDrive/Video_analysis/requirements.txt (line 36))\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.4.0->-r /content/drive/MyDrive/Video_analysis/requirements.txt (line 36))\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.4.0->-r /content/drive/MyDrive/Video_analysis/requirements.txt (line 36))\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.4.0->-r /content/drive/MyDrive/Video_analysis/requirements.txt (line 36))\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.4.0->-r /content/drive/MyDrive/Video_analysis/requirements.txt (line 36))\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.4.0->-r /content/drive/MyDrive/Video_analysis/requirements.txt (line 36))\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.4.0->-r /content/drive/MyDrive/Video_analysis/requirements.txt (line 36))\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch==2.4.0->-r /content/drive/MyDrive/Video_analysis/requirements.txt (line 36))\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.4.0->-r /content/drive/MyDrive/Video_analysis/requirements.txt (line 36))\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "INFO: pip is looking at multiple versions of torch to determine which version is compatible with other requirements. This could take a while.\n",
            "\u001b[31mERROR: Cannot install -r /content/drive/MyDrive/Video_analysis/requirements.txt (line 27) and -r /content/drive/MyDrive/Video_analysis/requirements.txt (line 36) because these package versions have conflicting dependencies.\u001b[0m\u001b[31m\n",
            "\u001b[0m\n",
            "The conflict is caused by:\n",
            "    openai-whisper 20231117 depends on triton<3 and >=2.0.0\n",
            "    torch 2.4.0 depends on triton==3.0.0; platform_system == \"Linux\" and platform_machine == \"x86_64\" and python_version < \"3.13\"\n",
            "\n",
            "To fix this you could try to:\n",
            "1. loosen the range of package versions you've specified\n",
            "2. remove package versions to allow pip to attempt to solve the dependency conflict\n",
            "\n",
            "\u001b[31mERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install whisper-timestamped"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "jZ2tTJan7m3G",
        "outputId": "4505bc26-9b5d-4d4e-b36f-029f5c2dc464"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting whisper-timestamped\n",
            "  Using cached whisper_timestamped-1.15.4-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.10/dist-packages (from whisper-timestamped) (3.0.10)\n",
            "Collecting dtw-python (from whisper-timestamped)\n",
            "  Using cached dtw_python-1.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
            "Collecting openai-whisper (from whisper-timestamped)\n",
            "  Using cached openai-whisper-20231117.tar.gz (798 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from dtw-python->whisper-timestamped) (1.13.1)\n",
            "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from dtw-python->whisper-timestamped) (1.26.4)\n",
            "Requirement already satisfied: triton<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper->whisper-timestamped) (2.3.1)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper->whisper-timestamped) (0.60.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper->whisper-timestamped) (2.3.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper->whisper-timestamped) (4.66.4)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper->whisper-timestamped) (10.3.0)\n",
            "Collecting tiktoken (from openai-whisper->whisper-timestamped)\n",
            "  Using cached tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton<3,>=2.0.0->openai-whisper->whisper-timestamped) (3.15.4)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper->whisper-timestamped) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper->whisper-timestamped) (2024.5.15)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper->whisper-timestamped) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper->whisper-timestamped) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper->whisper-timestamped) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper->whisper-timestamped) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper->whisper-timestamped) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper->whisper-timestamped) (2024.6.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->openai-whisper->whisper-timestamped)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->openai-whisper->whisper-timestamped)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->openai-whisper->whisper-timestamped)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->openai-whisper->whisper-timestamped)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->openai-whisper->whisper-timestamped)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->openai-whisper->whisper-timestamped)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->openai-whisper->whisper-timestamped)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->openai-whisper->whisper-timestamped)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->openai-whisper->whisper-timestamped)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch->openai-whisper->whisper-timestamped)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->openai-whisper->whisper-timestamped)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->openai-whisper->whisper-timestamped)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper->whisper-timestamped) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper->whisper-timestamped) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper->whisper-timestamped) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper->whisper-timestamped) (2024.7.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper->whisper-timestamped) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper->whisper-timestamped) (1.3.0)\n",
            "Downloading whisper_timestamped-1.15.4-py3-none-any.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.5/53.5 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dtw_python-1.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (770 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m770.5/770.5 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Downloading nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20231117-py3-none-any.whl size=801359 sha256=91596cce678592758a558c9b52622321544568340916a7877c47f73c7fe160b0\n",
            "  Stored in directory: /root/.cache/pip/wheels/d0/85/e1/9361b4cbea7dd4b7f6702fa4c3afc94877952eeb2b62f45f56\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, tiktoken, nvidia-cusparse-cu12, nvidia-cudnn-cu12, dtw-python, nvidia-cusolver-cu12, openai-whisper, whisper-timestamped\n",
            "Successfully installed dtw-python-1.5.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.20 nvidia-nvtx-cu12-12.1.105 openai-whisper-20231117 tiktoken-0.7.0 whisper-timestamped-1.15.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install streamlit -q"
      ],
      "metadata": {
        "id": "pJnxTACB75zg"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lWo7ZC5D8IHw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**connecting to stremlit**"
      ],
      "metadata": {
        "id": "RrILnAjP8Iev"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q -O - ipv4.icanhazip.com"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LqvGjIQJ759E",
        "outputId": "4bb37e54-dc64-4386-fe75-da9b02b38a04"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34.106.246.145\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# copy the code 34.106.246.145 and run below cell and proceed with yes and hit the url and in tunnel password put the above code 34.106.246.145"
      ],
      "metadata": {
        "id": "titOwad98OW1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! streamlit run /content/drive/MyDrive/Video_analysis/rapp.py & npx localtunnel --port 8501"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJRjd8xc8Dco",
        "outputId": "ea4c82b9-1753-49b3-a822-d084154cb216"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.106.246.145:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0JNeed to install the following packages:\n",
            "  localtunnel@2.0.2\n",
            "Ok to proceed? (y) \u001b[20Gy\n",
            "\u001b[K\u001b[?25hyour url is: https://yummy-buckets-love.loca.lt\n",
            "y\n",
            "error: XDG_RUNTIME_DIR not set in the environment.\n",
            "ALSA lib confmisc.c:855:(parse_card) cannot find card '0'\n",
            "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_card_inum returned error: No such file or directory\n",
            "ALSA lib confmisc.c:422:(snd_func_concat) error evaluating strings\n",
            "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_concat returned error: No such file or directory\n",
            "ALSA lib confmisc.c:1334:(snd_func_refer) error evaluating name\n",
            "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\n",
            "ALSA lib conf.c:5701:(snd_config_expand) Evaluate error: No such file or directory\n",
            "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM default\n",
            "ALSA lib confmisc.c:855:(parse_card) cannot find card '0'\n",
            "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_card_inum returned error: No such file or directory\n",
            "ALSA lib confmisc.c:422:(snd_func_concat) error evaluating strings\n",
            "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_concat returned error: No such file or directory\n",
            "ALSA lib confmisc.c:1334:(snd_func_refer) error evaluating name\n",
            "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\n",
            "ALSA lib conf.c:5701:(snd_config_expand) Evaluate error: No such file or directory\n",
            "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM default\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
            "MoviePy - Writing audio in extracted_audio.wav\n",
            "MoviePy - Done.\n",
            "100%|█████████████████████████████████████| 1.42G/1.42G [00:17<00:00, 85.7MiB/s]\n",
            "100% 6002/6002 [02:19<00:00, 43.15frames/s]\n",
            "{'text': \" Welcome to English in a Minute. This is a chip. Delicious. But why would someone have a chip on their shoulder? Dan, do you have any idea why Craig is mad at me? He's just got a chip on his shoulder. It still bothers him that you got that promotion instead of him. That was months ago. He needs to get over it. I agree. If someone has a chip on their shoulder, they feel angry about a past situation. They hold on to the belief that they were treated unfairly. This makes them generally unpleasant to be around. And that's English in a Minute.\", 'segments': [{'id': 0, 'seek': 0, 'start': 0.0, 'end': 13.82, 'text': ' Welcome to English in a Minute. This is a chip. Delicious. But why would someone have', 'tokens': [50364, 4027, 281, 3669, 294, 257, 33509, 13, 639, 307, 257, 11409, 13, 28518, 13, 583, 983, 576, 1580, 362, 51056], 'temperature': 0.0, 'avg_logprob': -0.16983431577682495, 'compression_ratio': 1.2761194029850746, 'no_speech_prob': 0.0020985743030905724, 'confidence': 0.817, 'words': [{'text': 'Welcome', 'start': 0.0, 'end': 4.64, 'confidence': 0.45}, {'text': 'to', 'start': 4.64, 'end': 5.06, 'confidence': 0.987}, {'text': 'English', 'start': 5.06, 'end': 5.44, 'confidence': 0.971}, {'text': 'in', 'start': 5.44, 'end': 5.62, 'confidence': 0.688}, {'text': 'a', 'start': 5.62, 'end': 5.74, 'confidence': 0.981}, {'text': 'Minute.', 'start': 5.74, 'end': 6.0, 'confidence': 0.796}, {'text': 'This', 'start': 6.64, 'end': 7.12, 'confidence': 0.601}, {'text': 'is', 'start': 7.12, 'end': 7.8, 'confidence': 0.96}, {'text': 'a', 'start': 7.8, 'end': 8.0, 'confidence': 0.978}, {'text': 'chip.', 'start': 8.0, 'end': 8.42, 'confidence': 0.937}, {'text': 'Delicious.', 'start': 10.66, 'end': 11.52, 'confidence': 0.645}, {'text': 'But', 'start': 12.12, 'end': 12.52, 'confidence': 0.797}, {'text': 'why', 'start': 12.52, 'end': 13.08, 'confidence': 0.844}, {'text': 'would', 'start': 13.08, 'end': 13.26, 'confidence': 0.974}, {'text': 'someone', 'start': 13.26, 'end': 13.56, 'confidence': 0.948}, {'text': 'have', 'start': 13.56, 'end': 13.82, 'confidence': 0.8}]}, {'id': 1, 'seek': 0, 'start': 13.88, 'end': 26.45, 'text': \" a chip on their shoulder? Dan, do you have any idea why Craig is mad at me? He's just\", 'tokens': [51056, 257, 11409, 322, 641, 7948, 30, 3394, 11, 360, 291, 362, 604, 1558, 983, 19732, 307, 5244, 412, 385, 30, 634, 311, 445, 51684], 'temperature': 0.0, 'avg_logprob': -0.16983431577682495, 'compression_ratio': 1.2761194029850746, 'no_speech_prob': 0.0020985743030905724, 'confidence': 0.937, 'words': [{'text': 'a', 'start': 13.88, 'end': 14.22, 'confidence': 0.993}, {'text': 'chip', 'start': 14.22, 'end': 14.6, 'confidence': 0.993}, {'text': 'on', 'start': 14.6, 'end': 15.74, 'confidence': 0.953}, {'text': 'their', 'start': 15.74, 'end': 16.08, 'confidence': 0.996}, {'text': 'shoulder?', 'start': 16.08, 'end': 16.58, 'confidence': 0.998}, {'text': 'Dan,', 'start': 20.42, 'end': 21.3, 'confidence': 0.718}, {'text': 'do', 'start': 21.7, 'end': 21.88, 'confidence': 0.995}, {'text': 'you', 'start': 21.88, 'end': 22.12, 'confidence': 0.998}, {'text': 'have', 'start': 22.12, 'end': 22.42, 'confidence': 0.998}, {'text': 'any', 'start': 22.42, 'end': 22.86, 'confidence': 0.995}, {'text': 'idea', 'start': 22.86, 'end': 23.38, 'confidence': 0.998}, {'text': 'why', 'start': 23.38, 'end': 24.02, 'confidence': 0.987}, {'text': 'Craig', 'start': 24.02, 'end': 24.56, 'confidence': 0.996}, {'text': 'is', 'start': 24.56, 'end': 24.98, 'confidence': 0.996}, {'text': 'mad', 'start': 24.98, 'end': 25.26, 'confidence': 0.988}, {'text': 'at', 'start': 25.26, 'end': 25.44, 'confidence': 0.827}, {'text': 'me?', 'start': 25.44, 'end': 25.68, 'confidence': 0.981}, {'text': \"He's\", 'start': 25.98, 'end': 26.3, 'confidence': 0.729}, {'text': 'just', 'start': 26.3, 'end': 26.45, 'confidence': 0.978}]}, {'id': 2, 'seek': 2640, 'start': 26.45, 'end': 31.78, 'text': ' got a chip on his shoulder. It still bothers him that you got that promotion instead of him.', 'tokens': [50364, 658, 257, 11409, 322, 702, 7948, 13, 467, 920, 33980, 796, 300, 291, 658, 300, 15783, 2602, 295, 796, 13, 50628], 'temperature': 0.0, 'avg_logprob': -0.1233213241786173, 'compression_ratio': 1.565217391304348, 'no_speech_prob': 0.14064526557922363, 'confidence': 0.968, 'words': [{'text': 'got', 'start': 26.45, 'end': 26.66, 'confidence': 0.989}, {'text': 'a', 'start': 26.66, 'end': 26.78, 'confidence': 0.99}, {'text': 'chip', 'start': 26.78, 'end': 26.94, 'confidence': 0.994}, {'text': 'on', 'start': 26.94, 'end': 27.1, 'confidence': 0.996}, {'text': 'his', 'start': 27.1, 'end': 27.32, 'confidence': 0.981}, {'text': 'shoulder.', 'start': 27.32, 'end': 27.7, 'confidence': 0.997}, {'text': 'It', 'start': 28.12, 'end': 28.26, 'confidence': 0.981}, {'text': 'still', 'start': 28.26, 'end': 28.52, 'confidence': 0.946}, {'text': 'bothers', 'start': 28.52, 'end': 28.9, 'confidence': 0.998}, {'text': 'him', 'start': 28.9, 'end': 29.22, 'confidence': 0.996}, {'text': 'that', 'start': 29.22, 'end': 29.48, 'confidence': 0.987}, {'text': 'you', 'start': 29.48, 'end': 29.66, 'confidence': 0.995}, {'text': 'got', 'start': 29.66, 'end': 29.84, 'confidence': 0.977}, {'text': 'that', 'start': 29.84, 'end': 30.06, 'confidence': 0.984}, {'text': 'promotion', 'start': 30.06, 'end': 30.56, 'confidence': 0.992}, {'text': 'instead', 'start': 30.56, 'end': 31.4, 'confidence': 0.862}, {'text': 'of', 'start': 31.4, 'end': 31.58, 'confidence': 0.997}, {'text': 'him.', 'start': 31.58, 'end': 31.78, 'confidence': 0.793}]}, {'id': 3, 'seek': 2640, 'start': 31.78, 'end': 42.41, 'text': ' That was months ago. He needs to get over it. I agree. If someone has a chip on their shoulder,', 'tokens': [50628, 663, 390, 2493, 2057, 13, 634, 2203, 281, 483, 670, 309, 13, 286, 3986, 13, 759, 1580, 575, 257, 11409, 322, 641, 7948, 11, 51176], 'temperature': 0.0, 'avg_logprob': -0.1233213241786173, 'compression_ratio': 1.565217391304348, 'no_speech_prob': 0.14064526557922363, 'confidence': 0.959, 'words': [{'text': 'That', 'start': 31.78, 'end': 32.64, 'confidence': 0.994}, {'text': 'was', 'start': 32.64, 'end': 33.02, 'confidence': 0.998}, {'text': 'months', 'start': 33.02, 'end': 33.4, 'confidence': 0.996}, {'text': 'ago.', 'start': 33.4, 'end': 33.96, 'confidence': 0.999}, {'text': 'He', 'start': 34.62, 'end': 34.88, 'confidence': 0.994}, {'text': 'needs', 'start': 34.88, 'end': 35.22, 'confidence': 0.998}, {'text': 'to', 'start': 35.22, 'end': 35.54, 'confidence': 0.999}, {'text': 'get', 'start': 35.54, 'end': 35.8, 'confidence': 0.995}, {'text': 'over', 'start': 35.8, 'end': 36.18, 'confidence': 0.998}, {'text': 'it.', 'start': 36.18, 'end': 36.54, 'confidence': 0.997}, {'text': 'I', 'start': 36.68, 'end': 37.1, 'confidence': 0.796}, {'text': 'agree.', 'start': 37.1, 'end': 37.5, 'confidence': 0.994}, {'text': 'If', 'start': 39.94, 'end': 40.28, 'confidence': 0.667}, {'text': 'someone', 'start': 40.28, 'end': 40.64, 'confidence': 0.997}, {'text': 'has', 'start': 40.64, 'end': 41.12, 'confidence': 0.993}, {'text': 'a', 'start': 41.12, 'end': 41.56, 'confidence': 0.987}, {'text': 'chip', 'start': 41.56, 'end': 41.84, 'confidence': 0.988}, {'text': 'on', 'start': 41.84, 'end': 42.1, 'confidence': 0.984}, {'text': 'their', 'start': 42.1, 'end': 42.28, 'confidence': 0.961}, {'text': 'shoulder,', 'start': 42.28, 'end': 42.41, 'confidence': 0.935}]}, {'id': 4, 'seek': 2640, 'start': 42.41, 'end': 50.98, 'text': ' they feel angry about a past situation. They hold on to the belief that they were treated unfairly.', 'tokens': [51176, 436, 841, 6884, 466, 257, 1791, 2590, 13, 814, 1797, 322, 281, 264, 7107, 300, 436, 645, 8668, 17019, 356, 13, 51580], 'temperature': 0.0, 'avg_logprob': -0.1233213241786173, 'compression_ratio': 1.565217391304348, 'no_speech_prob': 0.14064526557922363, 'confidence': 0.94, 'words': [{'text': 'they', 'start': 42.41, 'end': 43.32, 'confidence': 0.998}, {'text': 'feel', 'start': 43.32, 'end': 43.72, 'confidence': 0.998}, {'text': 'angry', 'start': 43.72, 'end': 44.28, 'confidence': 0.999}, {'text': 'about', 'start': 44.28, 'end': 44.8, 'confidence': 0.998}, {'text': 'a', 'start': 44.8, 'end': 45.06, 'confidence': 0.989}, {'text': 'past', 'start': 45.06, 'end': 45.36, 'confidence': 0.998}, {'text': 'situation.', 'start': 45.36, 'end': 46.06, 'confidence': 0.999}, {'text': 'They', 'start': 46.84, 'end': 47.14, 'confidence': 0.995}, {'text': 'hold', 'start': 47.14, 'end': 47.62, 'confidence': 0.999}, {'text': 'on', 'start': 47.62, 'end': 47.98, 'confidence': 0.604}, {'text': 'to', 'start': 47.98, 'end': 48.3, 'confidence': 0.997}, {'text': 'the', 'start': 48.3, 'end': 48.54, 'confidence': 0.997}, {'text': 'belief', 'start': 48.54, 'end': 48.86, 'confidence': 0.996}, {'text': 'that', 'start': 48.86, 'end': 49.12, 'confidence': 0.99}, {'text': 'they', 'start': 49.12, 'end': 49.28, 'confidence': 0.989}, {'text': 'were', 'start': 49.28, 'end': 49.54, 'confidence': 0.899}, {'text': 'treated', 'start': 49.54, 'end': 49.96, 'confidence': 0.969}, {'text': 'unfairly.', 'start': 49.96, 'end': 50.98, 'confidence': 0.787}]}, {'id': 5, 'seek': 5072, 'start': 51.02, 'end': 57.88, 'text': \" This makes them generally unpleasant to be around. And that's English in a Minute.\", 'tokens': [50388, 639, 1669, 552, 5101, 29128, 281, 312, 926, 13, 400, 300, 311, 3669, 294, 257, 33509, 13, 50716], 'temperature': 0.0, 'avg_logprob': -0.23704426288604735, 'compression_ratio': 1.0123456790123457, 'no_speech_prob': 0.04096771404147148, 'confidence': 0.944, 'words': [{'text': 'This', 'start': 51.02, 'end': 52.1, 'confidence': 0.829}, {'text': 'makes', 'start': 52.1, 'end': 52.36, 'confidence': 0.977}, {'text': 'them', 'start': 52.36, 'end': 52.84, 'confidence': 0.989}, {'text': 'generally', 'start': 52.84, 'end': 53.66, 'confidence': 0.882}, {'text': 'unpleasant', 'start': 53.66, 'end': 54.36, 'confidence': 0.974}, {'text': 'to', 'start': 54.36, 'end': 54.68, 'confidence': 0.958}, {'text': 'be', 'start': 54.68, 'end': 54.88, 'confidence': 0.993}, {'text': 'around.', 'start': 54.88, 'end': 55.2, 'confidence': 0.996}, {'text': 'And', 'start': 56.4, 'end': 56.58, 'confidence': 0.704}, {'text': \"that's\", 'start': 56.58, 'end': 57.04, 'confidence': 0.991}, {'text': 'English', 'start': 57.04, 'end': 57.38, 'confidence': 0.996}, {'text': 'in', 'start': 57.38, 'end': 57.58, 'confidence': 0.984}, {'text': 'a', 'start': 57.58, 'end': 57.66, 'confidence': 0.993}, {'text': 'Minute.', 'start': 57.66, 'end': 57.88, 'confidence': 0.952}]}], 'language': 'en'}\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
            "MoviePy - Writing audio in extracted_audio.wav\n",
            "MoviePy - Done.\n",
            "100% 6002/6002 [02:16<00:00, 44.05frames/s]\n",
            "{'text': \" Welcome to English in a Minute. This is a chip. Delicious. But why would someone have a chip on their shoulder? Dan, do you have any idea why Craig is mad at me? He's just got a chip on his shoulder. It still bothers him that you got that promotion instead of him. That was months ago. He needs to get over it. I agree. If someone has a chip on their shoulder, they feel angry about a past situation. They hold on to the belief that they were treated unfairly. This makes them generally unpleasant to be around. And that's English in a Minute.\", 'segments': [{'id': 0, 'seek': 0, 'start': 0.0, 'end': 13.82, 'text': ' Welcome to English in a Minute. This is a chip. Delicious. But why would someone have', 'tokens': [50364, 4027, 281, 3669, 294, 257, 33509, 13, 639, 307, 257, 11409, 13, 28518, 13, 583, 983, 576, 1580, 362, 51056], 'temperature': 0.0, 'avg_logprob': -0.16983431577682495, 'compression_ratio': 1.2761194029850746, 'no_speech_prob': 0.0020985743030905724, 'confidence': 0.817, 'words': [{'text': 'Welcome', 'start': 0.0, 'end': 4.64, 'confidence': 0.45}, {'text': 'to', 'start': 4.64, 'end': 5.06, 'confidence': 0.987}, {'text': 'English', 'start': 5.06, 'end': 5.44, 'confidence': 0.971}, {'text': 'in', 'start': 5.44, 'end': 5.62, 'confidence': 0.688}, {'text': 'a', 'start': 5.62, 'end': 5.74, 'confidence': 0.981}, {'text': 'Minute.', 'start': 5.74, 'end': 6.0, 'confidence': 0.796}, {'text': 'This', 'start': 6.64, 'end': 7.12, 'confidence': 0.601}, {'text': 'is', 'start': 7.12, 'end': 7.8, 'confidence': 0.96}, {'text': 'a', 'start': 7.8, 'end': 8.0, 'confidence': 0.978}, {'text': 'chip.', 'start': 8.0, 'end': 8.42, 'confidence': 0.937}, {'text': 'Delicious.', 'start': 10.66, 'end': 11.52, 'confidence': 0.645}, {'text': 'But', 'start': 12.12, 'end': 12.52, 'confidence': 0.797}, {'text': 'why', 'start': 12.52, 'end': 13.08, 'confidence': 0.844}, {'text': 'would', 'start': 13.08, 'end': 13.26, 'confidence': 0.974}, {'text': 'someone', 'start': 13.26, 'end': 13.56, 'confidence': 0.948}, {'text': 'have', 'start': 13.56, 'end': 13.82, 'confidence': 0.8}]}, {'id': 1, 'seek': 0, 'start': 13.88, 'end': 26.45, 'text': \" a chip on their shoulder? Dan, do you have any idea why Craig is mad at me? He's just\", 'tokens': [51056, 257, 11409, 322, 641, 7948, 30, 3394, 11, 360, 291, 362, 604, 1558, 983, 19732, 307, 5244, 412, 385, 30, 634, 311, 445, 51684], 'temperature': 0.0, 'avg_logprob': -0.16983431577682495, 'compression_ratio': 1.2761194029850746, 'no_speech_prob': 0.0020985743030905724, 'confidence': 0.937, 'words': [{'text': 'a', 'start': 13.88, 'end': 14.22, 'confidence': 0.993}, {'text': 'chip', 'start': 14.22, 'end': 14.6, 'confidence': 0.993}, {'text': 'on', 'start': 14.6, 'end': 15.74, 'confidence': 0.953}, {'text': 'their', 'start': 15.74, 'end': 16.08, 'confidence': 0.996}, {'text': 'shoulder?', 'start': 16.08, 'end': 16.58, 'confidence': 0.998}, {'text': 'Dan,', 'start': 20.42, 'end': 21.3, 'confidence': 0.718}, {'text': 'do', 'start': 21.7, 'end': 21.88, 'confidence': 0.995}, {'text': 'you', 'start': 21.88, 'end': 22.12, 'confidence': 0.998}, {'text': 'have', 'start': 22.12, 'end': 22.42, 'confidence': 0.998}, {'text': 'any', 'start': 22.42, 'end': 22.86, 'confidence': 0.995}, {'text': 'idea', 'start': 22.86, 'end': 23.38, 'confidence': 0.998}, {'text': 'why', 'start': 23.38, 'end': 24.02, 'confidence': 0.987}, {'text': 'Craig', 'start': 24.02, 'end': 24.56, 'confidence': 0.996}, {'text': 'is', 'start': 24.56, 'end': 24.98, 'confidence': 0.996}, {'text': 'mad', 'start': 24.98, 'end': 25.26, 'confidence': 0.988}, {'text': 'at', 'start': 25.26, 'end': 25.44, 'confidence': 0.827}, {'text': 'me?', 'start': 25.44, 'end': 25.68, 'confidence': 0.981}, {'text': \"He's\", 'start': 25.98, 'end': 26.3, 'confidence': 0.729}, {'text': 'just', 'start': 26.3, 'end': 26.45, 'confidence': 0.978}]}, {'id': 2, 'seek': 2640, 'start': 26.45, 'end': 31.78, 'text': ' got a chip on his shoulder. It still bothers him that you got that promotion instead of him.', 'tokens': [50364, 658, 257, 11409, 322, 702, 7948, 13, 467, 920, 33980, 796, 300, 291, 658, 300, 15783, 2602, 295, 796, 13, 50628], 'temperature': 0.0, 'avg_logprob': -0.1233213241786173, 'compression_ratio': 1.565217391304348, 'no_speech_prob': 0.14064526557922363, 'confidence': 0.968, 'words': [{'text': 'got', 'start': 26.45, 'end': 26.66, 'confidence': 0.989}, {'text': 'a', 'start': 26.66, 'end': 26.78, 'confidence': 0.99}, {'text': 'chip', 'start': 26.78, 'end': 26.94, 'confidence': 0.994}, {'text': 'on', 'start': 26.94, 'end': 27.1, 'confidence': 0.996}, {'text': 'his', 'start': 27.1, 'end': 27.32, 'confidence': 0.981}, {'text': 'shoulder.', 'start': 27.32, 'end': 27.7, 'confidence': 0.997}, {'text': 'It', 'start': 28.12, 'end': 28.26, 'confidence': 0.981}, {'text': 'still', 'start': 28.26, 'end': 28.52, 'confidence': 0.946}, {'text': 'bothers', 'start': 28.52, 'end': 28.9, 'confidence': 0.998}, {'text': 'him', 'start': 28.9, 'end': 29.22, 'confidence': 0.996}, {'text': 'that', 'start': 29.22, 'end': 29.48, 'confidence': 0.987}, {'text': 'you', 'start': 29.48, 'end': 29.66, 'confidence': 0.995}, {'text': 'got', 'start': 29.66, 'end': 29.84, 'confidence': 0.977}, {'text': 'that', 'start': 29.84, 'end': 30.06, 'confidence': 0.984}, {'text': 'promotion', 'start': 30.06, 'end': 30.56, 'confidence': 0.992}, {'text': 'instead', 'start': 30.56, 'end': 31.4, 'confidence': 0.862}, {'text': 'of', 'start': 31.4, 'end': 31.58, 'confidence': 0.997}, {'text': 'him.', 'start': 31.58, 'end': 31.78, 'confidence': 0.793}]}, {'id': 3, 'seek': 2640, 'start': 31.78, 'end': 42.41, 'text': ' That was months ago. He needs to get over it. I agree. If someone has a chip on their shoulder,', 'tokens': [50628, 663, 390, 2493, 2057, 13, 634, 2203, 281, 483, 670, 309, 13, 286, 3986, 13, 759, 1580, 575, 257, 11409, 322, 641, 7948, 11, 51176], 'temperature': 0.0, 'avg_logprob': -0.1233213241786173, 'compression_ratio': 1.565217391304348, 'no_speech_prob': 0.14064526557922363, 'confidence': 0.959, 'words': [{'text': 'That', 'start': 31.78, 'end': 32.64, 'confidence': 0.994}, {'text': 'was', 'start': 32.64, 'end': 33.02, 'confidence': 0.998}, {'text': 'months', 'start': 33.02, 'end': 33.4, 'confidence': 0.996}, {'text': 'ago.', 'start': 33.4, 'end': 33.96, 'confidence': 0.999}, {'text': 'He', 'start': 34.62, 'end': 34.88, 'confidence': 0.994}, {'text': 'needs', 'start': 34.88, 'end': 35.22, 'confidence': 0.998}, {'text': 'to', 'start': 35.22, 'end': 35.54, 'confidence': 0.999}, {'text': 'get', 'start': 35.54, 'end': 35.8, 'confidence': 0.995}, {'text': 'over', 'start': 35.8, 'end': 36.18, 'confidence': 0.998}, {'text': 'it.', 'start': 36.18, 'end': 36.54, 'confidence': 0.997}, {'text': 'I', 'start': 36.68, 'end': 37.1, 'confidence': 0.796}, {'text': 'agree.', 'start': 37.1, 'end': 37.5, 'confidence': 0.994}, {'text': 'If', 'start': 39.94, 'end': 40.28, 'confidence': 0.667}, {'text': 'someone', 'start': 40.28, 'end': 40.64, 'confidence': 0.997}, {'text': 'has', 'start': 40.64, 'end': 41.12, 'confidence': 0.993}, {'text': 'a', 'start': 41.12, 'end': 41.56, 'confidence': 0.987}, {'text': 'chip', 'start': 41.56, 'end': 41.84, 'confidence': 0.988}, {'text': 'on', 'start': 41.84, 'end': 42.1, 'confidence': 0.984}, {'text': 'their', 'start': 42.1, 'end': 42.28, 'confidence': 0.961}, {'text': 'shoulder,', 'start': 42.28, 'end': 42.41, 'confidence': 0.935}]}, {'id': 4, 'seek': 2640, 'start': 42.41, 'end': 50.98, 'text': ' they feel angry about a past situation. They hold on to the belief that they were treated unfairly.', 'tokens': [51176, 436, 841, 6884, 466, 257, 1791, 2590, 13, 814, 1797, 322, 281, 264, 7107, 300, 436, 645, 8668, 17019, 356, 13, 51580], 'temperature': 0.0, 'avg_logprob': -0.1233213241786173, 'compression_ratio': 1.565217391304348, 'no_speech_prob': 0.14064526557922363, 'confidence': 0.94, 'words': [{'text': 'they', 'start': 42.41, 'end': 43.32, 'confidence': 0.998}, {'text': 'feel', 'start': 43.32, 'end': 43.72, 'confidence': 0.998}, {'text': 'angry', 'start': 43.72, 'end': 44.28, 'confidence': 0.999}, {'text': 'about', 'start': 44.28, 'end': 44.8, 'confidence': 0.998}, {'text': 'a', 'start': 44.8, 'end': 45.06, 'confidence': 0.989}, {'text': 'past', 'start': 45.06, 'end': 45.36, 'confidence': 0.998}, {'text': 'situation.', 'start': 45.36, 'end': 46.06, 'confidence': 0.999}, {'text': 'They', 'start': 46.84, 'end': 47.14, 'confidence': 0.995}, {'text': 'hold', 'start': 47.14, 'end': 47.62, 'confidence': 0.999}, {'text': 'on', 'start': 47.62, 'end': 47.98, 'confidence': 0.604}, {'text': 'to', 'start': 47.98, 'end': 48.3, 'confidence': 0.997}, {'text': 'the', 'start': 48.3, 'end': 48.54, 'confidence': 0.997}, {'text': 'belief', 'start': 48.54, 'end': 48.86, 'confidence': 0.996}, {'text': 'that', 'start': 48.86, 'end': 49.12, 'confidence': 0.99}, {'text': 'they', 'start': 49.12, 'end': 49.28, 'confidence': 0.989}, {'text': 'were', 'start': 49.28, 'end': 49.54, 'confidence': 0.899}, {'text': 'treated', 'start': 49.54, 'end': 49.96, 'confidence': 0.969}, {'text': 'unfairly.', 'start': 49.96, 'end': 50.98, 'confidence': 0.787}]}, {'id': 5, 'seek': 5072, 'start': 51.02, 'end': 57.88, 'text': \" This makes them generally unpleasant to be around. And that's English in a Minute.\", 'tokens': [50388, 639, 1669, 552, 5101, 29128, 281, 312, 926, 13, 400, 300, 311, 3669, 294, 257, 33509, 13, 50716], 'temperature': 0.0, 'avg_logprob': -0.23704426288604735, 'compression_ratio': 1.0123456790123457, 'no_speech_prob': 0.04096771404147148, 'confidence': 0.944, 'words': [{'text': 'This', 'start': 51.02, 'end': 52.1, 'confidence': 0.829}, {'text': 'makes', 'start': 52.1, 'end': 52.36, 'confidence': 0.977}, {'text': 'them', 'start': 52.36, 'end': 52.84, 'confidence': 0.989}, {'text': 'generally', 'start': 52.84, 'end': 53.66, 'confidence': 0.882}, {'text': 'unpleasant', 'start': 53.66, 'end': 54.36, 'confidence': 0.974}, {'text': 'to', 'start': 54.36, 'end': 54.68, 'confidence': 0.958}, {'text': 'be', 'start': 54.68, 'end': 54.88, 'confidence': 0.993}, {'text': 'around.', 'start': 54.88, 'end': 55.2, 'confidence': 0.996}, {'text': 'And', 'start': 56.4, 'end': 56.58, 'confidence': 0.704}, {'text': \"that's\", 'start': 56.58, 'end': 57.04, 'confidence': 0.991}, {'text': 'English', 'start': 57.04, 'end': 57.38, 'confidence': 0.996}, {'text': 'in', 'start': 57.38, 'end': 57.58, 'confidence': 0.984}, {'text': 'a', 'start': 57.58, 'end': 57.66, 'confidence': 0.993}, {'text': 'Minute.', 'start': 57.66, 'end': 57.88, 'confidence': 0.952}]}], 'language': 'en'}\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
            "MoviePy - Writing audio in extracted_audio.wav\n",
            "MoviePy - Done.\n",
            "100% 7284/7284 [02:33<00:00, 47.46frames/s]\n",
            "{'text': \" Fail big. Today's the beginning of the rest of your life. So do what you feel passionate about. Take chances. Don't be afraid to fail. There's an old IQ test was nine dots and you had to draw five lines with a pencil within these nine dots without lifting the pencil. The only way to do it was to go outside the box. Don't be afraid to think outside the box. Don't be afraid to fail big. To dream big. But remember dreams without goals are just dreams and they ultimately fuel disappointment. So have dreams but have goals and understand that to achieve these goals you must apply discipline and consistency. You have to work at it every day. You have to plan every day. Hard work works. You\", 'segments': [{'id': 0, 'seek': 0, 'start': 0.32, 'end': 2.06, 'text': ' Fail big.', 'tokens': [50364, 39094, 955, 13, 50464], 'temperature': 0.0, 'avg_logprob': -0.21471415339289485, 'compression_ratio': 1.8310502283105023, 'no_speech_prob': 0.37732836604118347, 'confidence': 0.645, 'words': [{'text': 'Fail', 'start': 0.32, 'end': 1.18, 'confidence': 0.702}, {'text': 'big.', 'start': 1.18, 'end': 2.06, 'confidence': 0.592}]}, {'id': 1, 'seek': 0, 'start': 3.1, 'end': 8.1, 'text': \" Today's the beginning of the rest of your life. So do what you feel passionate about. Take chances.\", 'tokens': [50502, 2692, 311, 264, 2863, 295, 264, 1472, 295, 428, 993, 13, 407, 360, 437, 291, 841, 11410, 466, 13, 3664, 10486, 13, 50768], 'temperature': 0.0, 'avg_logprob': -0.21471415339289485, 'compression_ratio': 1.8310502283105023, 'no_speech_prob': 0.37732836604118347, 'confidence': 0.932, 'words': [{'text': \"Today's\", 'start': 3.1, 'end': 3.48, 'confidence': 0.776}, {'text': 'the', 'start': 3.48, 'end': 3.62, 'confidence': 0.997}, {'text': 'beginning', 'start': 3.62, 'end': 3.84, 'confidence': 0.999}, {'text': 'of', 'start': 3.84, 'end': 4.08, 'confidence': 0.999}, {'text': 'the', 'start': 4.08, 'end': 4.18, 'confidence': 0.999}, {'text': 'rest', 'start': 4.18, 'end': 4.42, 'confidence': 1.0}, {'text': 'of', 'start': 4.42, 'end': 4.58, 'confidence': 0.999}, {'text': 'your', 'start': 4.58, 'end': 4.7, 'confidence': 0.999}, {'text': 'life.', 'start': 4.7, 'end': 4.94, 'confidence': 0.996}, {'text': 'So', 'start': 4.96, 'end': 5.16, 'confidence': 0.885}, {'text': 'do', 'start': 5.16, 'end': 5.32, 'confidence': 0.923}, {'text': 'what', 'start': 5.32, 'end': 5.5, 'confidence': 0.999}, {'text': 'you', 'start': 5.5, 'end': 5.66, 'confidence': 1.0}, {'text': 'feel', 'start': 5.66, 'end': 5.94, 'confidence': 0.999}, {'text': 'passionate', 'start': 5.94, 'end': 6.42, 'confidence': 0.608}, {'text': 'about.', 'start': 6.42, 'end': 6.86, 'confidence': 0.996}, {'text': 'Take', 'start': 7.24, 'end': 7.52, 'confidence': 0.896}, {'text': 'chances.', 'start': 7.52, 'end': 8.1, 'confidence': 0.996}]}, {'id': 2, 'seek': 0, 'start': 9.28, 'end': 10.46, 'text': \" Don't be afraid to fail.\", 'tokens': [50808, 1468, 380, 312, 4638, 281, 3061, 13, 50883], 'temperature': 0.0, 'avg_logprob': -0.21471415339289485, 'compression_ratio': 1.8310502283105023, 'no_speech_prob': 0.37732836604118347, 'confidence': 0.999, 'words': [{'text': \"Don't\", 'start': 9.28, 'end': 9.46, 'confidence': 0.999}, {'text': 'be', 'start': 9.46, 'end': 9.64, 'confidence': 1.0}, {'text': 'afraid', 'start': 9.64, 'end': 10.0, 'confidence': 1.0}, {'text': 'to', 'start': 10.0, 'end': 10.3, 'confidence': 0.999}, {'text': 'fail.', 'start': 10.3, 'end': 10.46, 'confidence': 0.997}]}, {'id': 3, 'seek': 0, 'start': 10.52, 'end': 14.38, 'text': \" There's an old IQ test was nine dots and you had to\", 'tokens': [50883, 821, 311, 364, 1331, 28921, 1500, 390, 4949, 15026, 293, 291, 632, 281, 51073], 'temperature': 0.0, 'avg_logprob': -0.21471415339289485, 'compression_ratio': 1.8310502283105023, 'no_speech_prob': 0.37732836604118347, 'confidence': 0.89, 'words': [{'text': \"There's\", 'start': 10.52, 'end': 10.72, 'confidence': 0.851}, {'text': 'an', 'start': 10.72, 'end': 10.84, 'confidence': 0.914}, {'text': 'old', 'start': 10.84, 'end': 11.04, 'confidence': 0.986}, {'text': 'IQ', 'start': 11.04, 'end': 11.38, 'confidence': 0.988}, {'text': 'test', 'start': 11.38, 'end': 11.72, 'confidence': 0.977}, {'text': 'was', 'start': 11.72, 'end': 12.14, 'confidence': 0.68}, {'text': 'nine', 'start': 12.14, 'end': 12.68, 'confidence': 0.821}, {'text': 'dots', 'start': 12.68, 'end': 13.1, 'confidence': 0.995}, {'text': 'and', 'start': 13.1, 'end': 13.54, 'confidence': 0.632}, {'text': 'you', 'start': 13.54, 'end': 13.78, 'confidence': 0.998}, {'text': 'had', 'start': 13.78, 'end': 14.04, 'confidence': 0.994}, {'text': 'to', 'start': 14.04, 'end': 14.38, 'confidence': 0.998}]}, {'id': 4, 'seek': 0, 'start': 14.82, 'end': 19.02, 'text': ' draw five lines with a pencil within these nine dots without lifting the pencil.', 'tokens': [51086, 2642, 1732, 3876, 365, 257, 10985, 1951, 613, 4949, 15026, 1553, 15798, 264, 10985, 13, 51317], 'temperature': 0.0, 'avg_logprob': -0.21471415339289485, 'compression_ratio': 1.8310502283105023, 'no_speech_prob': 0.37732836604118347, 'confidence': 0.954, 'words': [{'text': 'draw', 'start': 14.82, 'end': 15.08, 'confidence': 0.909}, {'text': 'five', 'start': 15.08, 'end': 15.52, 'confidence': 0.984}, {'text': 'lines', 'start': 15.52, 'end': 15.9, 'confidence': 0.995}, {'text': 'with', 'start': 15.9, 'end': 16.1, 'confidence': 0.993}, {'text': 'a', 'start': 16.1, 'end': 16.28, 'confidence': 0.828}, {'text': 'pencil', 'start': 16.28, 'end': 16.6, 'confidence': 0.999}, {'text': 'within', 'start': 16.6, 'end': 16.88, 'confidence': 0.972}, {'text': 'these', 'start': 16.88, 'end': 17.16, 'confidence': 0.998}, {'text': 'nine', 'start': 17.16, 'end': 17.44, 'confidence': 0.987}, {'text': 'dots', 'start': 17.44, 'end': 17.78, 'confidence': 0.994}, {'text': 'without', 'start': 17.78, 'end': 18.22, 'confidence': 0.779}, {'text': 'lifting', 'start': 18.22, 'end': 18.54, 'confidence': 0.993}, {'text': 'the', 'start': 18.54, 'end': 18.8, 'confidence': 0.975}, {'text': 'pencil.', 'start': 18.8, 'end': 19.02, 'confidence': 0.98}]}, {'id': 5, 'seek': 0, 'start': 19.3, 'end': 24.87, 'text': \" The only way to do it was to go outside the box. Don't be afraid to think outside the box.\", 'tokens': [51317, 440, 787, 636, 281, 360, 309, 390, 281, 352, 2380, 264, 2424, 13, 1468, 380, 312, 4638, 281, 519, 2380, 264, 2424, 13, 51605], 'temperature': 0.0, 'avg_logprob': -0.21471415339289485, 'compression_ratio': 1.8310502283105023, 'no_speech_prob': 0.37732836604118347, 'confidence': 0.969, 'words': [{'text': 'The', 'start': 19.3, 'end': 19.44, 'confidence': 0.996}, {'text': 'only', 'start': 19.44, 'end': 19.62, 'confidence': 1.0}, {'text': 'way', 'start': 19.62, 'end': 19.84, 'confidence': 0.999}, {'text': 'to', 'start': 19.84, 'end': 19.94, 'confidence': 1.0}, {'text': 'do', 'start': 19.94, 'end': 20.06, 'confidence': 1.0}, {'text': 'it', 'start': 20.06, 'end': 20.2, 'confidence': 0.998}, {'text': 'was', 'start': 20.2, 'end': 20.38, 'confidence': 0.996}, {'text': 'to', 'start': 20.38, 'end': 20.52, 'confidence': 1.0}, {'text': 'go', 'start': 20.52, 'end': 20.7, 'confidence': 0.999}, {'text': 'outside', 'start': 20.7, 'end': 21.2, 'confidence': 0.999}, {'text': 'the', 'start': 21.2, 'end': 21.46, 'confidence': 0.997}, {'text': 'box.', 'start': 21.46, 'end': 21.82, 'confidence': 0.999}, {'text': \"Don't\", 'start': 21.98, 'end': 22.26, 'confidence': 0.784}, {'text': 'be', 'start': 22.26, 'end': 22.44, 'confidence': 0.999}, {'text': 'afraid', 'start': 22.44, 'end': 22.82, 'confidence': 1.0}, {'text': 'to', 'start': 22.82, 'end': 23.36, 'confidence': 0.999}, {'text': 'think', 'start': 23.36, 'end': 23.66, 'confidence': 0.963}, {'text': 'outside', 'start': 23.66, 'end': 24.42, 'confidence': 0.894}, {'text': 'the', 'start': 24.42, 'end': 24.72, 'confidence': 0.988}, {'text': 'box.', 'start': 24.72, 'end': 24.87, 'confidence': 0.999}]}, {'id': 6, 'seek': 0, 'start': 24.87, 'end': 28.68, 'text': \" Don't be afraid to fail big. To dream big.\", 'tokens': [51605, 1468, 380, 312, 4638, 281, 3061, 955, 13, 1407, 3055, 955, 13, 51788], 'temperature': 0.0, 'avg_logprob': -0.21471415339289485, 'compression_ratio': 1.8310502283105023, 'no_speech_prob': 0.37732836604118347, 'confidence': 0.961, 'words': [{'text': \"Don't\", 'start': 24.87, 'end': 25.14, 'confidence': 0.868}, {'text': 'be', 'start': 25.14, 'end': 25.3, 'confidence': 1.0}, {'text': 'afraid', 'start': 25.3, 'end': 25.68, 'confidence': 1.0}, {'text': 'to', 'start': 25.68, 'end': 26.06, 'confidence': 1.0}, {'text': 'fail', 'start': 26.06, 'end': 26.46, 'confidence': 0.989}, {'text': 'big.', 'start': 26.46, 'end': 26.98, 'confidence': 0.99}, {'text': 'To', 'start': 27.08, 'end': 27.4, 'confidence': 0.942}, {'text': 'dream', 'start': 27.4, 'end': 28.0, 'confidence': 0.989}, {'text': 'big.', 'start': 28.0, 'end': 28.68, 'confidence': 0.982}]}, {'id': 7, 'seek': 2848, 'start': 28.96, 'end': 35.34, 'text': ' But remember dreams without goals are just dreams and they ultimately fuel', 'tokens': [50368, 583, 1604, 7505, 1553, 5493, 366, 445, 7505, 293, 436, 6284, 6616, 50696], 'temperature': 0.0, 'avg_logprob': -0.22669817909361825, 'compression_ratio': 1.6473988439306357, 'no_speech_prob': 0.01892879605293274, 'confidence': 0.948, 'words': [{'text': 'But', 'start': 28.96, 'end': 29.16, 'confidence': 0.971}, {'text': 'remember', 'start': 29.16, 'end': 29.8, 'confidence': 0.984}, {'text': 'dreams', 'start': 29.8, 'end': 30.72, 'confidence': 0.751}, {'text': 'without', 'start': 30.72, 'end': 31.5, 'confidence': 0.904}, {'text': 'goals', 'start': 31.5, 'end': 32.22, 'confidence': 0.995}, {'text': 'are', 'start': 32.22, 'end': 32.76, 'confidence': 0.96}, {'text': 'just', 'start': 32.76, 'end': 33.04, 'confidence': 0.999}, {'text': 'dreams', 'start': 33.04, 'end': 33.58, 'confidence': 0.998}, {'text': 'and', 'start': 33.58, 'end': 34.0, 'confidence': 0.869}, {'text': 'they', 'start': 34.0, 'end': 34.22, 'confidence': 0.996}, {'text': 'ultimately', 'start': 34.22, 'end': 34.78, 'confidence': 0.996}, {'text': 'fuel', 'start': 34.78, 'end': 35.34, 'confidence': 0.989}]}, {'id': 8, 'seek': 2848, 'start': 35.54, 'end': 40.01, 'text': ' disappointment. So have dreams but have goals and', 'tokens': [50734, 28175, 13, 407, 362, 7505, 457, 362, 5493, 293, 50922], 'temperature': 0.0, 'avg_logprob': -0.22669817909361825, 'compression_ratio': 1.6473988439306357, 'no_speech_prob': 0.01892879605293274, 'confidence': 0.877, 'words': [{'text': 'disappointment.', 'start': 35.54, 'end': 36.5, 'confidence': 0.968}, {'text': 'So', 'start': 36.98, 'end': 37.34, 'confidence': 0.864}, {'text': 'have', 'start': 37.34, 'end': 37.62, 'confidence': 0.992}, {'text': 'dreams', 'start': 37.62, 'end': 38.3, 'confidence': 0.998}, {'text': 'but', 'start': 38.3, 'end': 38.68, 'confidence': 0.616}, {'text': 'have', 'start': 38.68, 'end': 38.9, 'confidence': 0.997}, {'text': 'goals', 'start': 38.9, 'end': 39.48, 'confidence': 0.997}, {'text': 'and', 'start': 39.48, 'end': 40.01, 'confidence': 0.688}]}, {'id': 9, 'seek': 2848, 'start': 40.01, 'end': 45.02, 'text': ' understand that to achieve these goals you must apply discipline and', 'tokens': [50944, 1223, 300, 281, 4584, 613, 5493, 291, 1633, 3079, 13635, 293, 51174], 'temperature': 0.0, 'avg_logprob': -0.22669817909361825, 'compression_ratio': 1.6473988439306357, 'no_speech_prob': 0.01892879605293274, 'confidence': 0.955, 'words': [{'text': 'understand', 'start': 40.01, 'end': 40.92, 'confidence': 0.955}, {'text': 'that', 'start': 40.92, 'end': 41.38, 'confidence': 0.996}, {'text': 'to', 'start': 41.38, 'end': 41.6, 'confidence': 0.998}, {'text': 'achieve', 'start': 41.6, 'end': 42.04, 'confidence': 1.0}, {'text': 'these', 'start': 42.04, 'end': 42.36, 'confidence': 0.999}, {'text': 'goals', 'start': 42.36, 'end': 42.86, 'confidence': 0.999}, {'text': 'you', 'start': 42.86, 'end': 43.26, 'confidence': 0.678}, {'text': 'must', 'start': 43.26, 'end': 43.52, 'confidence': 0.999}, {'text': 'apply', 'start': 43.52, 'end': 43.92, 'confidence': 0.997}, {'text': 'discipline', 'start': 43.92, 'end': 44.54, 'confidence': 0.968}, {'text': 'and', 'start': 44.54, 'end': 45.02, 'confidence': 0.978}]}, {'id': 10, 'seek': 2848, 'start': 45.1, 'end': 52.14, 'text': ' consistency. You have to work at it every day. You have to plan every day. Hard work works.', 'tokens': [51220, 14416, 13, 509, 362, 281, 589, 412, 309, 633, 786, 13, 509, 362, 281, 1393, 633, 786, 13, 11817, 589, 1985, 13, 51534], 'temperature': 0.0, 'avg_logprob': -0.22669817909361825, 'compression_ratio': 1.6473988439306357, 'no_speech_prob': 0.01892879605293274, 'confidence': 0.962, 'words': [{'text': 'consistency.', 'start': 45.1, 'end': 46.18, 'confidence': 0.965}, {'text': 'You', 'start': 46.72, 'end': 46.96, 'confidence': 0.978}, {'text': 'have', 'start': 46.96, 'end': 47.12, 'confidence': 1.0}, {'text': 'to', 'start': 47.12, 'end': 47.26, 'confidence': 1.0}, {'text': 'work', 'start': 47.26, 'end': 47.48, 'confidence': 1.0}, {'text': 'at', 'start': 47.48, 'end': 47.68, 'confidence': 0.996}, {'text': 'it', 'start': 47.68, 'end': 48.08, 'confidence': 0.997}, {'text': 'every', 'start': 48.08, 'end': 48.3, 'confidence': 0.83}, {'text': 'day.', 'start': 48.3, 'end': 48.46, 'confidence': 0.999}, {'text': 'You', 'start': 48.48, 'end': 48.58, 'confidence': 0.989}, {'text': 'have', 'start': 48.58, 'end': 48.76, 'confidence': 1.0}, {'text': 'to', 'start': 48.76, 'end': 49.0, 'confidence': 0.999}, {'text': 'plan', 'start': 49.0, 'end': 49.48, 'confidence': 0.997}, {'text': 'every', 'start': 49.48, 'end': 50.0, 'confidence': 0.897}, {'text': 'day.', 'start': 50.0, 'end': 50.34, 'confidence': 0.999}, {'text': 'Hard', 'start': 50.46, 'end': 50.84, 'confidence': 0.807}, {'text': 'work', 'start': 50.84, 'end': 51.36, 'confidence': 0.992}, {'text': 'works.', 'start': 51.36, 'end': 52.14, 'confidence': 0.91}]}, {'id': 11, 'seek': 5848, 'start': 58.48, 'end': 59.8, 'text': ' You', 'tokens': [50364, 509, 50464], 'temperature': 0.0, 'avg_logprob': -0.8894182443618774, 'compression_ratio': 0.2727272727272727, 'no_speech_prob': 0.6382632255554199, 'confidence': 0.327, 'words': [{'text': 'You', 'start': 58.48, 'end': 59.8, 'confidence': 0.327}]}], 'language': 'en'}\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ]
    }
  ]
}